{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n","metadata":{"execution":{"iopub.status.busy":"2023-01-03T09:08:12.848069Z","iopub.execute_input":"2023-01-03T09:08:12.848530Z","iopub.status.idle":"2023-01-03T09:09:15.482199Z","shell.execute_reply.started":"2023-01-03T09:08:12.848447Z","shell.execute_reply":"2023-01-03T09:09:15.481112Z"},"_kg_hide-output":true,"scrolled":true,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  6034  100  6034    0     0  45256      0 --:--:-- --:--:-- --:--:-- 45368\nUpdating... This may take around 2 minutes.\nUpdating TPU runtime to pytorch-nightly ...\nFound existing installation: torch 1.7.1+cpu\nUninstalling torch-1.7.1+cpu:\n  Successfully uninstalled torch-1.7.1+cpu\nFound existing installation: torchvision 0.8.2+cpu\nUninstalling torchvision-0.8.2+cpu:\n  Successfully uninstalled torchvision-0.8.2+cpu\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCopying gs://tpu-pytorch/wheels/colab/torch-nightly-cp37-cp37m-linux_x86_64.whl...\n- [1 files][116.0 MiB/116.0 MiB]                                                \nOperation completed over 1 objects/116.0 MiB.                                    \nCopying gs://tpu-pytorch/wheels/colab/torch_xla-nightly-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][149.5 MiB/149.5 MiB]                                                \nOperation completed over 1 objects/149.5 MiB.                                    \nCopying gs://tpu-pytorch/wheels/colab/torchvision-nightly-cp37-cp37m-linux_x86_64.whl...\n/ [1 files][  6.0 MiB/  6.0 MiB]                                                \nOperation completed over 1 objects/6.0 MiB.                                      \nProcessing ./torch-nightly-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (3.7.4.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (1.8)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (2.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (21.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->torch==nightly) (5.0.9)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torch==nightly) (2.4.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.7/site-packages (from sympy->torch==nightly) (1.2.1)\nDone updating TPU runtime\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\neasyocr 1.4.1 requires torchvision>=0.5, which is not installed.\nallennlp 2.7.0 requires torchvision<0.11.0,>=0.8.1, which is not installed.\ntorchtext 0.8.1 requires torch==1.7.1, but you have torch 2.0.0a0+git39d49db which is incompatible.\ntorchaudio 0.7.2 requires torch==1.7.1, but you have torch 2.0.0a0+git39d49db which is incompatible.\npytorch-ignite 0.4.6 requires torch<2,>=1.3, but you have torch 2.0.0a0+git39d49db which is incompatible.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 2.0.0a0+git39d49db which is incompatible.\nallennlp 2.7.0 requires torch<1.10.0,>=1.6.0, but you have torch 2.0.0a0+git39d49db which is incompatible.\u001b[0m\nSuccessfully installed torch-2.0.0a0+git39d49db\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nProcessing ./torch_xla-nightly-cp37-cp37m-linux_x86_64.whl\nCollecting absl-py>=1.0.0\n  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n\u001b[K     |████████████████████████████████| 124 kB 4.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: cloud-tpu-client>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from torch-xla==nightly) (0.10)\nRequirement already satisfied: google-api-python-client==1.8.0 in /opt/conda/lib/python3.7/site-packages (from cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.8.0)\nRequirement already satisfied: oauth2client in /opt/conda/lib/python3.7/site-packages (from cloud-tpu-client>=0.10.0->torch-xla==nightly) (4.1.3)\nRequirement already satisfied: google-auth>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.34.0)\nRequirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.19.1)\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.1.0)\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.0.1)\nRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.31.1)\nRequirement already satisfied: six<2dev,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.15.0)\nRequirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (57.4.0)\nRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (21.0)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2021.1)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2.25.1)\nRequirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (3.18.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.53.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (4.2.2)\nRequirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2.4.7)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (0.4.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2021.5.30)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla==nightly) (4.0.0)\nInstalling collected packages: absl-py, torch-xla\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.12.0\n    Uninstalling absl-py-0.12.0:\n      Successfully uninstalled absl-py-0.12.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.4.1 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\ntensorflow-metadata 1.2.0 requires absl-py<0.13,>=0.9, but you have absl-py 1.3.0 which is incompatible.\u001b[0m\nSuccessfully installed absl-py-1.3.0 torch-xla-2.0.0+1858e8b\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nProcessing ./torchvision-nightly-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (3.7.4.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.19.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (8.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (2.25.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (2.0.0a0+git39d49db)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==nightly) (2021.5.30)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==nightly) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==nightly) (1.26.6)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==nightly) (2.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (21.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (1.8)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (2.5)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->torch->torchvision==nightly) (5.0.9)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torch->torchvision==nightly) (2.4.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.7/site-packages (from sympy->torch->torchvision==nightly) (1.2.1)\nInstalling collected packages: torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 2.0.0a0+git39d49db which is incompatible.\nfastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.15.0a0+32d254b which is incompatible.\nallennlp 2.7.0 requires torch<1.10.0,>=1.6.0, but you have torch 2.0.0a0+git39d49db which is incompatible.\nallennlp 2.7.0 requires torchvision<0.11.0,>=0.8.1, but you have torchvision 0.15.0a0+32d254b which is incompatible.\u001b[0m\nSuccessfully installed torchvision-0.15.0a0+32d254b\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  libomp5 libopenblas-dev\n0 upgraded, 2 newly installed, 0 to remove and 18 not upgraded.\nNeed to get 4094 kB of archives.\nAfter this operation, 54.2 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\nFetched 4094 kB in 0s (9247 kB/s)\ndebconf: delaying package configuration, since apt-utils is not installed\nSelecting previously unselected package libopenblas-dev:amd64.\n(Reading database ... 106894 files and directories currently installed.)\nPreparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libomp5:amd64.\nPreparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\nUnpacking libomp5:amd64 (5.0.1-1) ...\nSetting up libomp5:amd64 (5.0.1-1) ...\nSetting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\nProcessing triggers for libc-bin (2.27-3ubuntu1.4) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoModelForSequenceClassification\nimport torch\nimport torch.nn.functional as F\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp\n\ndevice = xm.xla_device()\n\nclass Classifier(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        self.bert = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n        # Also include followers and following\n        self.layer2 = nn.Linear(2, 1, bias=True)\n        \n    def forward(self, x):\n        out = torch.zeros((x.shape[0], 2), device=device)\n        bert_out = self.bert(x[:, :512].long(), x[:, 512:1024].long()).to_tuple()[0]\n        out[:, :2] = bert_out\n        res = self.layer2(out)\n        return torch.relu(res)\nmodel = Classifier()\n\nmodel.load_state_dict(torch.load(\"../input/pretrained/model.bin\"))\n# model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T09:09:48.554387Z","iopub.execute_input":"2023-01-03T09:09:48.554643Z","iopub.status.idle":"2023-01-03T09:10:09.979535Z","shell.execute_reply.started":"2023-01-03T09:09:48.554619Z","shell.execute_reply":"2023-01-03T09:10:09.978732Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch_xla/core/xla_model.py:261: UserWarning: Failed to initialize NumPy: module compiled against API version 0xe but this version of numpy is 0xd (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n  return torch.device(device)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce46c93be0cd454d9b68797613d7c7c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0af9deda369a434aa0edd32bf88c4b96"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from transformers import AutoTokenizer\n# import numpy as np\n# # Let's precompute the tokenized versions and pickle it.\n# df = pd.read_json(\"../input/tweets/merged_troll_data.json\")\n# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\n# encoded = df['content'][:100000].apply(lambda x :tokenizer(x, max_length=512, padding=\"max_length\", truncation=True)).to_numpy()\n\n# np.save(\"encoded.npy\", encoded)\n\n# encoded = np.load(\"encoded.npy\", allow_pickle=True)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import Dataset\nimport numpy as np\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\nclass TweetData(Dataset):\n    \n    def __init__(self, file_path):\n        df = pd.read_json(file_path)\n        \n        self.labels = torch.tensor(df['troll'].values, dtype=torch.bool)\n        self.content = df['content']\n#         self.followers = torch.tensor(df['followers'].to_numpy()).float()\n#         self.following = torch.tensor(df['following'].to_numpy()).float()\n#         self.followers = self.followers / (self.followers.max() - self.followers.min())\n#         self.following = self.following / (self.following.max() - self.following.min())\n        \n    def __len__(self):\n        return self.labels.shape[0]\n        \n    def __getitem__(self, idx):\n        # Retrieve item\n        res = torch.zeros((1024))\n        encoded = tokenizer(self.content[idx], max_length=512, padding=\"max_length\", truncation=True)\n        res[:512] = torch.tensor(encoded['input_ids'])\n        res[512:1024] = torch.tensor(encoded['attention_mask'])\n#         res[1024] = self.followers[idx]\n#         res[1025] = self.following[idx]\n        return res, self.labels[idx].reshape((1)).float()\n        \n\ndata = TweetData(\"../input/tweets/merged_troll_data.json\")","metadata":{"execution":{"iopub.status.busy":"2023-01-03T09:11:33.908817Z","iopub.execute_input":"2023-01-03T09:11:33.909474Z","iopub.status.idle":"2023-01-03T09:11:39.004093Z","shell.execute_reply.started":"2023-01-03T09:11:33.909413Z","shell.execute_reply":"2023-01-03T09:11:39.002905Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e5dc188296c4d32b5dd5a20663375f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33204d19dc4045119945f780d4c37628"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cb1f0b238784a2a83980ae11d7ca55e"}},"metadata":{}}]},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader\n\ntrain_size, test_size = int(0.8*len(data)), int(0.2*len(data))+1\n\ntrain_set, val_set = torch.utils.data.random_split(data, [train_size, test_size])\n\ntrain_sampler = torch.utils.data.distributed.DistributedSampler(\n          train_set,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=True)\n\nvalid_sampler = torch.utils.data.distributed.DistributedSampler(\n          val_set,\n          num_replicas=xm.xrt_world_size(),\n          rank=xm.get_ordinal(),\n          shuffle=False)\n\ntrain_dataloader = DataLoader(\n          train_set,\n            num_workers=4,\n            sampler = train_sampler,\n            batch_size=64)\n\nval_dataloader = DataLoader(\n                        val_set,\n                        num_workers=4,\n                        batch_size=64,\n                        sampler = valid_sampler,\n                        drop_last=False\n                       )\n\ndevice = xm.xla_device()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T09:11:39.005703Z","iopub.execute_input":"2023-01-03T09:11:39.005974Z","iopub.status.idle":"2023-01-03T09:11:39.974701Z","shell.execute_reply.started":"2023-01-03T09:11:39.005950Z","shell.execute_reply":"2023-01-03T09:11:39.973972Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"%env TOKENIZERS_PARALLELISM=true","metadata":{"execution":{"iopub.status.busy":"2023-01-03T09:11:40.165040Z","iopub.execute_input":"2023-01-03T09:11:40.165402Z","iopub.status.idle":"2023-01-03T09:11:40.171518Z","shell.execute_reply.started":"2023-01-03T09:11:40.165368Z","shell.execute_reply":"2023-01-03T09:11:40.170696Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# for TPU\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n# device = xm.xla_device()\n# torch.set_default_tensor_type('torch.FloatTensor')\nimport numpy as np\nimport torch_xla.utils.serialization as xser\ndevice = xm.xla_device()\nmodel = model.to(device)\n\nmax_epochs = 3\nlearning_rate = 0.4 * 1e-5\nbatch_size = 1000\nloss_func = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n\n\nepochs, loss = 0, float(\"inf\")\n\n\ndef train_func_loop(loader, mod, opt, dev):\n    print(\"Starting batch!\")\n    \n    losses = []\n    for batch_idx, (batch, target) in enumerate(loader,1):\n        batch = batch.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n        \n        out = mod(batch)\n        loss = loss_func(out, target.float())\n        losses.append(loss.item())\n        \n        loss.backward()\n        opt.step()\n        \n        optimizer.zero_grad()\n        \n        if batch_idx % 20 == 0:\n            print(np.array(losses).mean())\n            losses = []\n        if (batch_idx + 1) % 200 == 0:\n            torch_xla.core.xla_model.save(model.state_dict(), f\"model.bin\", master_only=True)\n        if (batch_idx + 1) % 2000 == 0:\n            torch_xla.core.xla_model.save(model.state_dict(), f\"model.bin\", master_only=True)\n\n# def val_func_loop(loader, mod, opt, dev):\n#     print(\"Starting batch!\")\n    \n#     losses = []\n#     for batch_idx, (batch, target) in enumerate(loader,1):\n#         batch = batch.to(device, dtype=torch.float)\n#         target = target.to(device, dtype=torch.float)\n        \n#         out = mod(batch)\n#         loss = loss_func(out, target.float())\n#         losses.append(loss.item())\n        \n#         if batch_idx % 10 == 0:\n#             print(np.array(losses).mean())\n#             losses = []\n#         if (batch_idx + 1) % 1000 == 0:\n#             return\n\ndef epochLoop():\n    print(\"Starting epoch!\")\n    para_loader = pl.ParallelLoader(train_dataloader, [device])\n    train_func_loop(para_loader.per_device_loader(device), model, optimizer, device)\n\n    val_loader = pl.ParallelLoader(val_dataloader, [device])\n    #val_func_loop(para_loader.per_device_loader(device), model, device)\n    \ndef _mp_fn(rank, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = epochLoop()\n    \nFLAGS = {}\n# applying multiprocessing so that images get trained different on      # cores of kaggle-tpuFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1, start_method='fork')\n\nprint(\"Done!\")\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:33:58.253765Z","iopub.execute_input":"2023-01-03T15:33:58.254087Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Starting epoch!\nStarting batch!\n0.10837347935885192\n0.12289521135389805\n0.12252630367875099\n0.12007163278758526\n0.11837301217019558\n0.12279433496296406\n0.12167486548423767\n0.11727854683995247\n0.11650890223681927\n0.12132159098982812\n0.11012225262820721\n0.10946258436888456\n0.10925718508660794\n0.1183034785091877\n0.12720774300396442\n0.10973196178674698\n0.11256753914058208\n0.10660698376595974\n0.11386845111846924\n0.10076332353055477\n0.10473614372313023\n0.11202005296945572\n0.1160534955561161\n0.10805297568440438\n0.11870592683553696\n0.12076152116060257\n0.11637314409017563\n0.11953723356127739\n0.10834940373897553\n0.11233472265303135\n0.11999274268746377\n0.1227375477552414\n0.11783444173634053\n0.12358365952968597\n0.12693694271147252\n0.11989331431686878\n0.10818891823291779\n0.12613968104124068\n0.11897119134664536\n0.12291390486061574\n0.12344372682273388\n0.13238167352974414\n0.12433116100728511\n0.12450432367622852\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch_xla.utils.serialization as xser\ntorch_xla.core.xla_model.save(model.state_dict(), f\"model.bin\", master_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-03T15:33:41.620078Z","iopub.execute_input":"2023-01-03T15:33:41.620559Z","iopub.status.idle":"2023-01-03T15:33:44.307905Z","shell.execute_reply.started":"2023-01-03T15:33:41.620512Z","shell.execute_reply":"2023-01-03T15:33:44.306703Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n\ndef val_func_loop(loader, mod, opt, dev):\n    print(\"Starting batch!\")\n    \n    losses = []\n    for batch_idx, (batch, target) in enumerate(loader,1):\n        batch = batch.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n        \n        out = mod(batch)\n        loss = loss_func(out, target.float())\n        losses.append(loss.item())\n        \n        if batch_idx % 10 == 0:\n            print(np.array(losses).mean())\n            losses = []\n            \n\nval_loader = pl.ParallelLoader(val_dataloader, [device])\nval_func_loop(val_loader.per_device_loader(device), model, optimizer, device)\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}